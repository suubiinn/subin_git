{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49817076-7727-4de8-b022-325b4c2933a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Activation, Dense, Flatten\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.utils.layer_utils import get_source_inputs\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import layer_utils\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator #이미지 데이터를 tensor로 변한하기 위해 활용되는 라이브러리입니다.\n",
    "import glob\n",
    "warnings.filterwarnings('ignore')\n",
    "# tf.random.set_seed(49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5c83b4b-88ef-44a1-9225-0bc3db6c47c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = 'https://github.com/GKalliatakis/Keras-VGG16-places365/releases/download/v1.0/vgg16-places365_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/GKalliatakis/Keras-VGG16-places365/releases/download/v1.0/vgg16-places365_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "def vgg16(weights_path, top=True):\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Block 1\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Block 2\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add( Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add( MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Block 3\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add( Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add( Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add( MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Block 4\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Block 5\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    if top:\n",
    "        # Classification layer\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(4096, activation='relu'))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(4096, activation='relu'))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(365, activation='softmax'))\n",
    "        \n",
    "    # else:\n",
    "    #     model.add( GlobalAveragePooling2D())\n",
    "    \n",
    "    model.load_weights(filepath=weights_path)\n",
    "\n",
    "    sgd = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cdd5b51-e783-461d-bd70-c4bdb4f49a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                       featurewise_center=True,\n",
    "                                       featurewise_std_normalization=True,\n",
    "                                       zoom_range=0.2,\n",
    "                                       channel_shift_range=0.1,\n",
    "                                       rotation_range=20,\n",
    "                                       width_shift_range=0.2,\n",
    "                                       height_shift_range=0.2,\n",
    "                                       horizontal_flip=True\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f11bf25c-ba0b-4cd4-9b98-26aeac928e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 344 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = 'C:\\\\Users\\\\pc\\\\Desktop\\\\DLmodel_database\\\\Trainingdataset'\n",
    "# test_path = \"C:\\Users\\pc\\Desktop\\photo O\\photo_0_500_in\\\\korea_url54\"\n",
    "image_size = (224,224)\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=image_size,\n",
    "    shuffle=True,\n",
    "    batch_size=344,\n",
    "    class_mode = 'categorical',\n",
    "    color_mode='rgb',\n",
    "    # seed=49\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55fcd582-fbaf-415e-b6e3-35f995846ebb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DirectoryIterator in module keras.preprocessing.image object:\n",
      "\n",
      "class DirectoryIterator(BatchFromFilesMixin, Iterator)\n",
      " |  DirectoryIterator(directory, image_data_generator, target_size=(256, 256), color_mode='rgb', classes=None, class_mode='categorical', batch_size=32, shuffle=True, seed=None, data_format=None, save_to_dir=None, save_prefix='', save_format='png', follow_links=False, subset=None, interpolation='nearest', keep_aspect_ratio=False, dtype=None)\n",
      " |  \n",
      " |  Iterator capable of reading images from a directory on disk.\n",
      " |  \n",
      " |  Deprecated: `tf.keras.preprocessing.image.DirectoryIterator` is not\n",
      " |  recommended for new code. Prefer loading images with\n",
      " |  `tf.keras.utils.image_dataset_from_directory` and transforming the output\n",
      " |  `tf.data.Dataset` with preprocessing layers. For more information, see the\n",
      " |  tutorials for [loading images](\n",
      " |  https://www.tensorflow.org/tutorials/load_data/images) and\n",
      " |  [augmenting images](\n",
      " |  https://www.tensorflow.org/tutorials/images/data_augmentation), as well as\n",
      " |  the [preprocessing layer guide](\n",
      " |  https://www.tensorflow.org/guide/keras/preprocessing_layers).\n",
      " |  \n",
      " |  Args:\n",
      " |      directory: Path to the directory to read images from. Each subdirectory in\n",
      " |        this directory will be considered to contain images from one class, or\n",
      " |        alternatively you could specify class subdirectories via the `classes`\n",
      " |        argument.\n",
      " |      image_data_generator: Instance of `ImageDataGenerator` to use for random\n",
      " |        transformations and normalization.\n",
      " |      target_size: tuple of integers, dimensions to resize input images to.\n",
      " |      color_mode: One of `\"rgb\"`, `\"rgba\"`, `\"grayscale\"`. Color mode to read\n",
      " |        images.\n",
      " |      classes: Optional list of strings, names of subdirectories containing\n",
      " |        images from each class (e.g. `[\"dogs\", \"cats\"]`). It will be computed\n",
      " |        automatically if not set.\n",
      " |      class_mode: Mode for yielding the targets:\n",
      " |          - `\"binary\"`: binary targets (if there are only two classes),\n",
      " |          - `\"categorical\"`: categorical targets,\n",
      " |          - `\"sparse\"`: integer targets,\n",
      " |          - `\"input\"`: targets are images identical to input images (mainly used\n",
      " |            to work with autoencoders),\n",
      " |          - `None`: no targets get yielded (only input images are yielded).\n",
      " |      batch_size: Integer, size of a batch.\n",
      " |      shuffle: Boolean, whether to shuffle the data between epochs.\n",
      " |      seed: Random seed for data shuffling.\n",
      " |      data_format: String, one of `channels_first`, `channels_last`.\n",
      " |      save_to_dir: Optional directory where to save the pictures being yielded,\n",
      " |        in a viewable format. This is useful for visualizing the random\n",
      " |        transformations being applied, for debugging purposes.\n",
      " |      save_prefix: String prefix to use for saving sample images (if\n",
      " |        `save_to_dir` is set).\n",
      " |      save_format: Format to use for saving sample images (if `save_to_dir` is\n",
      " |        set).\n",
      " |      subset: Subset of data (`\"training\"` or `\"validation\"`) if\n",
      " |        validation_split is set in ImageDataGenerator.\n",
      " |      interpolation: Interpolation method used to resample the image if the\n",
      " |        target size is different from that of the loaded image. Supported\n",
      " |        methods are \"nearest\", \"bilinear\", and \"bicubic\". If PIL version 1.1.3\n",
      " |        or newer is installed, \"lanczos\" is also supported. If PIL version 3.4.0\n",
      " |        or newer is installed, \"box\" and \"hamming\" are also supported. By\n",
      " |        default, \"nearest\" is used.\n",
      " |      keep_aspect_ratio: Boolean, whether to resize images to a target size\n",
      " |          without aspect ratio distortion. The image is cropped in the center\n",
      " |          with target aspect ratio before resizing.\n",
      " |      dtype: Dtype to use for generated arrays.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DirectoryIterator\n",
      " |      BatchFromFilesMixin\n",
      " |      Iterator\n",
      " |      keras.utils.data_utils.Sequence\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, directory, image_data_generator, target_size=(256, 256), color_mode='rgb', classes=None, class_mode='categorical', batch_size=32, shuffle=True, seed=None, data_format=None, save_to_dir=None, save_prefix='', save_format='png', follow_links=False, subset=None, interpolation='nearest', keep_aspect_ratio=False, dtype=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  filepaths\n",
      " |      List of absolute paths to image files.\n",
      " |  \n",
      " |  labels\n",
      " |      Class labels of every observation.\n",
      " |  \n",
      " |  sample_weight\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  allowed_class_modes = {'binary', 'categorical', None, 'input', 'sparse...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BatchFromFilesMixin:\n",
      " |  \n",
      " |  set_processing_attrs(self, image_data_generator, target_size, color_mode, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, keep_aspect_ratio)\n",
      " |      Sets attributes to use later for processing files into a batch.\n",
      " |      \n",
      " |      Args:\n",
      " |          image_data_generator: Instance of `ImageDataGenerator`\n",
      " |              to use for random transformations and normalization.\n",
      " |          target_size: tuple of integers, dimensions to resize input images\n",
      " |          to.\n",
      " |          color_mode: One of `\"rgb\"`, `\"rgba\"`, `\"grayscale\"`.\n",
      " |              Color mode to read images.\n",
      " |          data_format: String, one of `channels_first`, `channels_last`.\n",
      " |          save_to_dir: Optional directory where to save the pictures\n",
      " |              being yielded, in a viewable format. This is useful\n",
      " |              for visualizing the random transformations being\n",
      " |              applied, for debugging purposes.\n",
      " |          save_prefix: String prefix to use for saving sample\n",
      " |              images (if `save_to_dir` is set).\n",
      " |          save_format: Format to use for saving sample images\n",
      " |              (if `save_to_dir` is set).\n",
      " |          subset: Subset of data (`\"training\"` or `\"validation\"`) if\n",
      " |              validation_split is set in ImageDataGenerator.\n",
      " |          interpolation: Interpolation method used to resample the image if the\n",
      " |              target size is different from that of the loaded image.\n",
      " |              Supported methods are \"nearest\", \"bilinear\", and \"bicubic\".\n",
      " |              If PIL version 1.1.3 or newer is installed, \"lanczos\" is also\n",
      " |              supported. If PIL version 3.4.0 or newer is installed, \"box\" and\n",
      " |              \"hamming\" are also supported. By default, \"nearest\" is used.\n",
      " |          keep_aspect_ratio: Boolean, whether to resize images to a target size\n",
      " |              without aspect ratio distortion. The image is cropped in the center\n",
      " |              with target aspect ratio before resizing.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BatchFromFilesMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Iterator:\n",
      " |  \n",
      " |  __getitem__(self, idx)\n",
      " |      Gets batch at position `index`.\n",
      " |      \n",
      " |      Args:\n",
      " |          index: position of the batch in the Sequence.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A batch\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Create a generator that iterate over the Sequence.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Number of batch in the Sequence.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The number of batches in the Sequence.\n",
      " |  \n",
      " |  __next__(self, *args, **kwargs)\n",
      " |  \n",
      " |  next(self)\n",
      " |      For python 2.x.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The next batch.\n",
      " |  \n",
      " |  on_epoch_end(self)\n",
      " |      Method called at the end of every epoch.\n",
      " |  \n",
      " |  reset(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from Iterator:\n",
      " |  \n",
      " |  white_list_formats = ('png', 'jpg', 'jpeg', 'bmp', 'ppm', 'tif', 'tiff...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e833cce-83ef-434b-b6ba-ce74005dd4b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#없앨 인덱스 번호\n",
    "# del_folder = glob.glob(\"C:\\\\Users\\\\pc\\\\Desktop\\\\photo O\\\\photo_0_500_in\\\\korea_url*\")\n",
    "\n",
    "# num = len(\"C:\\\\Users\\\\pc\\\\Desktop\\\\photo O\\\\photo_0_500_in\\\\korea_url\")\n",
    "# a=[]\n",
    "# b=[]\n",
    "# c=[]\n",
    "# for i in del_folder:\n",
    "#     if len(i[num:])==1:\n",
    "#         a.append(i)\n",
    "#     elif len(i[num:])==2:\n",
    "#         b.append(i)\n",
    "#     else:\n",
    "#         c.append(i)\n",
    "# d=[]\n",
    "# for i in a:\n",
    "#     d.append(i)\n",
    "# for i in b:\n",
    "#     d.append(i)\n",
    "# for i in c:\n",
    "#     d.append(i)\n",
    "# del_index = [i[num:] for i in d]\n",
    "# len(del_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e95cb43-6a4f-4bd1-996f-3b79f9312056",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 딥러닝 돌릴 url\n",
    "folder = glob.glob(\"C:\\\\Users\\\\pc\\\\Desktop\\\\0-200\\\\0-200\\\\plus_url*\")\n",
    "num = len(\"D:\\\\나눔\\\\지석 800-1000\\\\plus_url\")\n",
    "a=[]\n",
    "b=[]\n",
    "c=[]\n",
    "for i in folder:\n",
    "    if len(i[num:])==1:\n",
    "        a.append(i)\n",
    "    elif len(i[num:])==2:\n",
    "        b.append(i)\n",
    "    else:\n",
    "        c.append(i)\n",
    "\n",
    "d=[]\n",
    "for i in a:\n",
    "    d.append(i)\n",
    "for i in b:\n",
    "    d.append(i)\n",
    "for i in c:\n",
    "    d.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ea09a15-536e-4548-9f06-802f69907d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52d9460d-9e7a-4864-bce5-c3a9f19a3427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_path = folder[0]\n",
    "# test_data = train_datagen.flow_from_directory(\n",
    "#     test_path,\n",
    "#     target_size=image_size,\n",
    "#     shuffle=True,\n",
    "#     batch_size=32,\n",
    "#     class_mode = 'categorical'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c13070e9-e140-4221-b84a-77f5ccde19c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "weights_file = 'vgg16-places365_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "weights_path = tf.keras.utils.get_file(weights_file, WEIGHTS_PATH_NO_TOP)\n",
    "base_model = vgg16(weights_path, top=False)\n",
    "base_model.trainable = False\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.Flatten())\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38621b1e-89ab-41cd-9cc9-eb6a47e4a447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.backend.set_image_data_format('channels_last')\n",
    "# weights_file = 'vgg16-places365_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "# weights_path = tf.keras.utils.get_file(weights_file, WEIGHTS_PATH_NO_TOP)\n",
    "# base_model = vgg16(weights_path, top=False)\n",
    "# base_model.trainable = False\n",
    "# model = tf.keras.models.Sequential()\n",
    "# model.add(base_model)\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(128, activation='relu'))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.Dense(256, activation='relu'))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.Dense(512, activation='relu'))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.Dense(1024, activation='relu'))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.Dense(2048, activation='relu'))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.Dense(4096, activation='relu'))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e91fa1da-b929-4702-8911-19daa89dfb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.backend.set_image_data_format('channels_last')\n",
    "# weights_file = 'vgg16-places365_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "# weights_path = tf.keras.utils.get_file(weights_file, WEIGHTS_PATH_NO_TOP)\n",
    "# base_model = vgg16(weights_path, top=False)\n",
    "# base_model.trainable = False\n",
    "# model = tf.keras.models.Sequential()\n",
    "# model.add(base_model)\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(128, activation='relu'))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.Dense(256, activation='relu'))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.Dense(512, activation='relu'))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.Dense(1024, activation='relu'))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.Dense(2048, activation='relu'))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.Dense(4096, activation='relu'))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.Dense(2048, activation='relu'))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.Dense(1024, activation='relu'))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.Dense(512, activation='relu'))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.Dense(256, activation='relu'))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.Dense(128, activation='relu'))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5014c9b9-d9b0-4d4e-92fc-691631613f6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 2.4174 - accuracy: 0.2820\n",
      "Epoch 1: accuracy improved from -inf to 0.28198, saving model to checkpoints\\vgg16_12.h5\n",
      "11/11 [==============================] - 20s 1s/step - loss: 2.4174 - accuracy: 0.2820\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.6903 - accuracy: 0.3721\n",
      "Epoch 2: accuracy improved from 0.28198 to 0.37209, saving model to checkpoints\\vgg16_12.h5\n",
      "11/11 [==============================] - 7s 616ms/step - loss: 1.6903 - accuracy: 0.3721\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.4665 - accuracy: 0.4157\n",
      "Epoch 3: accuracy improved from 0.37209 to 0.41570, saving model to checkpoints\\vgg16_12.h5\n",
      "11/11 [==============================] - 7s 628ms/step - loss: 1.4665 - accuracy: 0.4157\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.3761 - accuracy: 0.4360\n",
      "Epoch 4: accuracy improved from 0.41570 to 0.43605, saving model to checkpoints\\vgg16_12.h5\n",
      "11/11 [==============================] - 7s 629ms/step - loss: 1.3761 - accuracy: 0.4360\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.3702 - accuracy: 0.5029\n",
      "Epoch 5: accuracy improved from 0.43605 to 0.50291, saving model to checkpoints\\vgg16_12.h5\n",
      "11/11 [==============================] - 7s 620ms/step - loss: 1.3702 - accuracy: 0.5029\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.2117 - accuracy: 0.5116\n",
      "Epoch 6: accuracy improved from 0.50291 to 0.51163, saving model to checkpoints\\vgg16_12.h5\n",
      "11/11 [==============================] - 7s 641ms/step - loss: 1.2117 - accuracy: 0.5116\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.1977 - accuracy: 0.5203\n",
      "Epoch 7: accuracy improved from 0.51163 to 0.52035, saving model to checkpoints\\vgg16_12.h5\n",
      "11/11 [==============================] - 7s 603ms/step - loss: 1.1977 - accuracy: 0.5203\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.1418 - accuracy: 0.5610\n",
      "Epoch 8: accuracy improved from 0.52035 to 0.56105, saving model to checkpoints\\vgg16_12.h5\n",
      "11/11 [==============================] - 7s 643ms/step - loss: 1.1418 - accuracy: 0.5610\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.1655 - accuracy: 0.5552\n",
      "Epoch 9: accuracy did not improve from 0.56105\n",
      "11/11 [==============================] - 4s 375ms/step - loss: 1.1655 - accuracy: 0.5552\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.0806 - accuracy: 0.5785\n",
      "Epoch 10: accuracy improved from 0.56105 to 0.57849, saving model to checkpoints\\vgg16_12.h5\n",
      "11/11 [==============================] - 7s 612ms/step - loss: 1.0806 - accuracy: 0.5785\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.1415 - accuracy: 0.5320\n",
      "Epoch 11: accuracy did not improve from 0.57849\n",
      "11/11 [==============================] - 4s 377ms/step - loss: 1.1415 - accuracy: 0.5320\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9456 - accuracy: 0.6395\n",
      "Epoch 12: accuracy improved from 0.57849 to 0.63953, saving model to checkpoints\\vgg16_12.h5\n",
      "11/11 [==============================] - 7s 625ms/step - loss: 0.9456 - accuracy: 0.6395\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8912 - accuracy: 0.6192\n",
      "Epoch 13: accuracy did not improve from 0.63953\n",
      "11/11 [==============================] - 4s 392ms/step - loss: 0.8912 - accuracy: 0.6192\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9220 - accuracy: 0.6192\n",
      "Epoch 14: accuracy did not improve from 0.63953\n",
      "11/11 [==============================] - 5s 396ms/step - loss: 0.9220 - accuracy: 0.6192\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9416 - accuracy: 0.5872\n",
      "Epoch 15: accuracy did not improve from 0.63953\n",
      "11/11 [==============================] - 4s 366ms/step - loss: 0.9416 - accuracy: 0.5872\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.0162 - accuracy: 0.5959\n",
      "Epoch 16: accuracy did not improve from 0.63953\n",
      "11/11 [==============================] - 4s 375ms/step - loss: 1.0162 - accuracy: 0.5959\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9603 - accuracy: 0.6105\n",
      "Epoch 17: accuracy did not improve from 0.63953\n",
      "11/11 [==============================] - 4s 366ms/step - loss: 0.9603 - accuracy: 0.6105\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9168 - accuracy: 0.6134\n",
      "Epoch 18: accuracy did not improve from 0.63953\n",
      "11/11 [==============================] - 4s 378ms/step - loss: 0.9168 - accuracy: 0.6134\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9073 - accuracy: 0.6337\n",
      "Epoch 19: accuracy did not improve from 0.63953\n",
      "11/11 [==============================] - 4s 378ms/step - loss: 0.9073 - accuracy: 0.6337\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8396 - accuracy: 0.6628\n",
      "Epoch 20: accuracy improved from 0.63953 to 0.66279, saving model to checkpoints\\vgg16_12.h5\n",
      "11/11 [==============================] - 7s 646ms/step - loss: 0.8396 - accuracy: 0.6628\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9226 - accuracy: 0.6250\n",
      "Epoch 21: accuracy did not improve from 0.66279\n",
      "11/11 [==============================] - 4s 374ms/step - loss: 0.9226 - accuracy: 0.6250\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8283 - accuracy: 0.6599\n",
      "Epoch 22: accuracy did not improve from 0.66279\n",
      "11/11 [==============================] - 4s 345ms/step - loss: 0.8283 - accuracy: 0.6599\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7889 - accuracy: 0.6657\n",
      "Epoch 23: accuracy improved from 0.66279 to 0.66570, saving model to checkpoints\\vgg16_12.h5\n",
      "11/11 [==============================] - 7s 596ms/step - loss: 0.7889 - accuracy: 0.6657\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7679 - accuracy: 0.6744\n",
      "Epoch 24: accuracy improved from 0.66570 to 0.67442, saving model to checkpoints\\vgg16_12.h5\n",
      "11/11 [==============================] - 6s 572ms/step - loss: 0.7679 - accuracy: 0.6744\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7686 - accuracy: 0.6948\n",
      "Epoch 25: accuracy improved from 0.67442 to 0.69477, saving model to checkpoints\\vgg16_12.h5\n",
      "11/11 [==============================] - 7s 634ms/step - loss: 0.7686 - accuracy: 0.6948\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7888 - accuracy: 0.6802\n",
      "Epoch 26: accuracy did not improve from 0.69477\n",
      "11/11 [==============================] - 4s 360ms/step - loss: 0.7888 - accuracy: 0.6802\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7777 - accuracy: 0.6773\n",
      "Epoch 27: accuracy did not improve from 0.69477\n",
      "11/11 [==============================] - 4s 362ms/step - loss: 0.7777 - accuracy: 0.6773\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7522 - accuracy: 0.7093\n",
      "Epoch 28: accuracy improved from 0.69477 to 0.70930, saving model to checkpoints\\vgg16_12.h5\n",
      "11/11 [==============================] - 7s 673ms/step - loss: 0.7522 - accuracy: 0.7093\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8040 - accuracy: 0.7093\n",
      "Epoch 29: accuracy did not improve from 0.70930\n",
      "11/11 [==============================] - 4s 351ms/step - loss: 0.8040 - accuracy: 0.7093\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7362 - accuracy: 0.7006\n",
      "Epoch 30: accuracy did not improve from 0.70930\n",
      "11/11 [==============================] - 4s 352ms/step - loss: 0.7362 - accuracy: 0.7006\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7091 - accuracy: 0.7180\n",
      "Epoch 31: accuracy improved from 0.70930 to 0.71802, saving model to checkpoints\\vgg16_12.h5\n",
      "11/11 [==============================] - 7s 654ms/step - loss: 0.7091 - accuracy: 0.7180\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7090 - accuracy: 0.7326\n",
      "Epoch 32: accuracy improved from 0.71802 to 0.73256, saving model to checkpoints\\vgg16_12.h5\n",
      "11/11 [==============================] - 7s 615ms/step - loss: 0.7090 - accuracy: 0.7326\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7637 - accuracy: 0.7093\n",
      "Epoch 33: accuracy did not improve from 0.73256\n",
      "11/11 [==============================] - 4s 368ms/step - loss: 0.7637 - accuracy: 0.7093\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.6577 - accuracy: 0.7500\n",
      "Epoch 34: accuracy improved from 0.73256 to 0.75000, saving model to checkpoints\\vgg16_12.h5\n",
      "11/11 [==============================] - 6s 580ms/step - loss: 0.6577 - accuracy: 0.7500\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7599 - accuracy: 0.7151\n",
      "Epoch 35: accuracy did not improve from 0.75000\n",
      "11/11 [==============================] - 4s 345ms/step - loss: 0.7599 - accuracy: 0.7151\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.6147 - accuracy: 0.7558\n",
      "Epoch 36: accuracy improved from 0.75000 to 0.75581, saving model to checkpoints\\vgg16_12.h5\n",
      "11/11 [==============================] - 7s 611ms/step - loss: 0.6147 - accuracy: 0.7558\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.6866 - accuracy: 0.7529\n",
      "Epoch 37: accuracy did not improve from 0.75581\n",
      "11/11 [==============================] - 4s 370ms/step - loss: 0.6866 - accuracy: 0.7529\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.6222 - accuracy: 0.7471\n",
      "Epoch 38: accuracy did not improve from 0.75581\n",
      "11/11 [==============================] - 4s 390ms/step - loss: 0.6222 - accuracy: 0.7471\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.6549 - accuracy: 0.7209\n",
      "Epoch 39: accuracy did not improve from 0.75581\n",
      "11/11 [==============================] - 4s 380ms/step - loss: 0.6549 - accuracy: 0.7209\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.6742 - accuracy: 0.7703\n",
      "Epoch 40: accuracy improved from 0.75581 to 0.77035, saving model to checkpoints\\vgg16_12.h5\n",
      "11/11 [==============================] - 7s 626ms/step - loss: 0.6742 - accuracy: 0.7703\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7306 - accuracy: 0.7064\n",
      "Epoch 41: accuracy did not improve from 0.77035\n",
      "11/11 [==============================] - 4s 365ms/step - loss: 0.7306 - accuracy: 0.7064\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7351 - accuracy: 0.6860\n",
      "Epoch 42: accuracy did not improve from 0.77035\n",
      "11/11 [==============================] - 4s 359ms/step - loss: 0.7351 - accuracy: 0.6860\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.6314 - accuracy: 0.7413\n",
      "Epoch 43: accuracy did not improve from 0.77035\n",
      "11/11 [==============================] - 4s 373ms/step - loss: 0.6314 - accuracy: 0.7413\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.6772 - accuracy: 0.7413\n",
      "Epoch 44: accuracy did not improve from 0.77035\n",
      "11/11 [==============================] - 4s 367ms/step - loss: 0.6772 - accuracy: 0.7413\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.6159 - accuracy: 0.7413\n",
      "Epoch 45: accuracy did not improve from 0.77035\n",
      "11/11 [==============================] - 4s 363ms/step - loss: 0.6159 - accuracy: 0.7413\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.6500 - accuracy: 0.7355\n",
      "Epoch 46: accuracy did not improve from 0.77035\n",
      "11/11 [==============================] - 4s 385ms/step - loss: 0.6500 - accuracy: 0.7355\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7118 - accuracy: 0.7267\n",
      "Epoch 47: accuracy did not improve from 0.77035\n",
      "11/11 [==============================] - 5s 401ms/step - loss: 0.7118 - accuracy: 0.7267\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.5836 - accuracy: 0.7645\n",
      "Epoch 48: accuracy did not improve from 0.77035\n",
      "11/11 [==============================] - 4s 381ms/step - loss: 0.5836 - accuracy: 0.7645\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7197 - accuracy: 0.7151\n",
      "Epoch 49: accuracy did not improve from 0.77035\n",
      "11/11 [==============================] - 4s 360ms/step - loss: 0.7197 - accuracy: 0.7151\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.6536 - accuracy: 0.7297\n",
      "Epoch 50: accuracy did not improve from 0.77035\n",
      "11/11 [==============================] - 5s 401ms/step - loss: 0.6536 - accuracy: 0.7297\n",
      "Epoch 50: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "checkpoint = ModelCheckpoint(\"checkpoints/vgg16_12.h5\", monitor='accuracy', verbose=1, save_best_only=True )\n",
    "early = EarlyStopping(monitor='accuracy', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "history = model.fit(\n",
    "        train_data,\n",
    "        callbacks=[checkpoint, early],\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        verbose=1)\n",
    "#러닝레이트 0.01에서 0.0001로 늘리고 base model의 globalpooling을 주석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ab94e7d-3571-4df2-8652-4a49f99cdff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 17s 836ms/step - loss: 0.1425 - accuracy: 0.9506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14250613749027252, 0.9505813717842102]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.save(\"room.h5\")\n",
    "model.evaluate(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "434b6a32-30d4-4eb9-b3e9-acc8dafae4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f96ff61-d831-4ae3-ba97-089b8f6475ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"room.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4be6e805-c3d8-431c-ba14-2dd2a7b00508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 20s 877ms/step - loss: 0.1809 - accuracy: 0.9360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18093939125537872, 0.9360465407371521]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57daabd7-abcb-4cfd-a803-1ab585837cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 2s 167ms/step\n"
     ]
    }
   ],
   "source": [
    "batch = next(train_data)\n",
    "images,label= batch# 0번 이미지데이터 1번 레이블\n",
    "labels = model.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2adf4616-8546-4a47-b5d4-344732fb71b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score :  0.9302325581395349\n",
      "recall_score :  0.9302325581395349\n",
      "precision_score :  0.9562167729930888\n",
      "f1_score :  0.9406220236035329\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy_score : \",accuracy_score(label, np.round(labels)))\n",
    "print(\"recall_score : \", recall_score(label, np.round(labels),average='macro'))\n",
    "print(\"precision_score : \",precision_score(label, np.round(labels),average='macro'))\n",
    "print(\"f1_score : \",f1_score(label, np.round(labels),average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d2af9b6a-8013-49fa-9a24-d4bbb958376b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-5b2ee04c3d5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mrecall_precision_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-49-5b2ee04c3d5a>\u001b[0m in \u001b[0;36mrecall_precision_plot\u001b[1;34m(y_true, y_scores)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_scores\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# y_scores 를 thresholds 처럼 사용했음\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mrecall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_recall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mprecision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_precision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_scores\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-5b2ee04c3d5a>\u001b[0m in \u001b[0;36mget_recall\u001b[1;34m(y_true, y_scores, threshold)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_recall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_scores\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mpredict_positive_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_scores\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpredict_positive_num\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mground_truth\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-5b2ee04c3d5a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_recall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_scores\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mpredict_positive_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_scores\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpredict_positive_num\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mground_truth\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "def get_recall(y_true,y_scores,threshold):\n",
    "    predict_positive_num = len(y_scores[y_scores >= threshold])\n",
    "    tp = len( [x for x in y_true[:predict_positive_num] if x == 1] )\n",
    "    ground_truth  = len(y_true[y_true==1])\n",
    "    recall = tp / ground_truth\n",
    "    return recall\n",
    "\n",
    "def get_precision(y_true,y_scores,threshold):\n",
    "    predict_positive_num = len(y_scores[y_scores >= threshold])\n",
    "    tp = len( [x for x in y_true[:predict_positive_num] if x == 1] )\n",
    "    fp = len( [x for x in y_true[:predict_positive_num] if x == 0] )\n",
    "    precision = tp / (tp + fp) \n",
    "    return precision \n",
    "\n",
    "def recall_precision_plot(y_true, y_scores):\n",
    "    recall, precision = [] , []\n",
    "\n",
    "    for _ in y_scores: # y_scores 를 thresholds 처럼 사용했음\n",
    "        recall.append(get_recall(y_true, y_scores, _ ))\n",
    "        precision.append(get_precision(y_true,y_scores,_))\n",
    "\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "\n",
    "    #3d container\n",
    "    ax = plt.axes(projection = '3d')\n",
    "    #3d scatter plot\n",
    "    ax.plot3D(recall, y_scores, precision)\n",
    "    ax.scatter3D(recall,y_scores,precision)\n",
    "    #give labels\n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.set_ylabel('Thresholds')\n",
    "    ax.set_zlabel('Precision')\n",
    "    ax.set_title('Precision-Recall Curve 3D')  \n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure(figsize = (9,6))\n",
    "    plt.plot(recall, precision)\n",
    "    plt.scatter(recall,precision)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve 2D')\n",
    "    plt.show()\n",
    "    \n",
    "recall_precision_plot(label,np.round(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a580800e-29e2-4004-9766-f2c13e02791c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.]], dtype=float32),\n",
       " array([[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label, np.round(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33238d0f-35e2-4013-9b0d-630603d36ef7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/sequential_1/dense/MatMul/MatMul_1' defined at (most recent call last):\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\pc\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\pc\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\tornado\\ioloop.py\", line 687, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\tornado\\ioloop.py\", line 740, in _run_callback\n      ret = callback()\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\tornado\\gen.py\", line 821, in inner\n      self.ctx_run(self.run)\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\tornado\\gen.py\", line 782, in run\n      yielded = self.gen.send(value)\n    File \"C:\\Users\\pc\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"C:\\Users\\pc\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"C:\\Users\\pc\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"C:\\Users\\pc\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\pc\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2866, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3071, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-7-8916dca7b2c6>\", line 6, in <module>\n      history = model.fit(\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential_1/dense/MatMul/MatMul_1'\nOOM when allocating tensor with shape[25088,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/sequential_1/dense/MatMul/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_7840]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8916dca7b2c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mearly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/sequential_1/dense/MatMul/MatMul_1' defined at (most recent call last):\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\pc\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\pc\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\tornado\\ioloop.py\", line 687, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\tornado\\ioloop.py\", line 740, in _run_callback\n      ret = callback()\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\tornado\\gen.py\", line 821, in inner\n      self.ctx_run(self.run)\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\tornado\\gen.py\", line 782, in run\n      yielded = self.gen.send(value)\n    File \"C:\\Users\\pc\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"C:\\Users\\pc\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"C:\\Users\\pc\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"C:\\Users\\pc\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\pc\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2866, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3071, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-7-8916dca7b2c6>\", line 6, in <module>\n      history = model.fit(\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"C:\\Users\\pc\\anaconda3\\envs\\gpu-py\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential_1/dense/MatMul/MatMul_1'\nOOM when allocating tensor with shape[25088,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/sequential_1/dense/MatMul/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_7840]"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "checkpoint = ModelCheckpoint(\"checkpoints/vgg16_12.h5\", monitor='accuracy', verbose=1, save_best_only=True )\n",
    "early = EarlyStopping(monitor='accuracy', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "history = model.fit(\n",
    "        train_data,\n",
    "        callbacks=[checkpoint, early],\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d026e2-c09a-4d10-b2e7-e809c67c1d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c76b566-87c1-4181-ad1c-fd5561295e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('room.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10091cca-9ace-4580-8912-4a6a5e5ca3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c9a2e0cc-7861-4eae-9591-fdbf39694112",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\"Casual\",\"Classic\",\"Modern\",\"Natural\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c3016465-5d81-4656-b3d7-6a6141908763",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url0\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url1\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url10\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url100\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url101\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url102\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url103\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url104\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url105\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url106\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url107\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url108\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url109\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url11\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url110\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url111\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url112\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url113\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url114\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url115\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url116\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url117\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url118\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url119\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url12\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url120\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url121\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url122\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url123\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url124\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url125\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url126\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url127\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url128\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url129\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url13\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url130\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url131\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url132\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url133\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url134\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url135\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url136\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url137\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url138\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url139\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url14\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url140\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url141\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url142\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url143\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url144\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url145\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url146\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url147\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url148\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url149\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url15\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url150\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url151\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url152\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url153\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url154\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url155\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url156\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url157\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url158\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url159\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url16\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url160\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url161\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url162\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url163\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url164\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url165\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url166\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url167\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url168\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url169\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url17\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url170\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url171\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url172\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url173\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url174\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url175\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url176\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url177\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url178\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url179\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url18\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url180\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url181\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url182\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url183\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url184\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url185\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url186\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url187\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url188\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url189\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url19\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url190\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url191\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url192\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url193\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url194\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url195\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url196\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url197\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url198\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url199\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url2\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url20\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url21\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url22\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url23\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url24\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url25\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url26\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url27\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url28\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url29\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url3\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url30\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url31\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url32\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url33\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url34\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url35\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url36\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url37\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url38\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url39\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url4\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url40\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url41\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url42\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url43\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url44\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url45\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url46\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url47\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url48\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url49\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url5\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url50\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url51\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url52\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url53\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url54\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url55\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url56\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url57\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url58\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url59\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url6\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url60\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url61\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url62\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url63\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url64\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url65\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url66\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url67\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url68\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url69\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url7\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url70\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url71\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url72\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url73\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url74\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url75\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url76\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url77\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url78\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url79\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url8\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url80\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url81\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url82\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url83\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url84\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url85\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url86\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url87\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url88\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url89\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url9\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url90\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url91\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url92\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url93\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url94\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url95\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url96\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url97\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url98\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Found 10 images belonging to 1 classes.\n",
      "C:\\Users\\pc\\Desktop\\0-200\\0-200\\plus_url99\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "#데이터 프레임 만들고 예측\n",
    "df = pd.DataFrame(columns=[\"Photo\",\"Casual\",\"Classic\",\"Modern\",\"Natural\"])\n",
    "\n",
    "test_path = d\n",
    "\n",
    "for i in test_path:\n",
    "    test_data = train_datagen.flow_from_directory(\n",
    "        i,\n",
    "        target_size=image_size,\n",
    "        shuffle=True,\n",
    "        batch_size=32,\n",
    "        class_mode = 'categorical' #2d 원핫인코딩\n",
    "    )\n",
    "    print(i)\n",
    "    batch = next(test_data)\n",
    "    images= batch[0]# 0번 이미지데이터 1번 레이블\n",
    "    labels = model.predict(images)    \n",
    "    sum_Caual=0\n",
    "    sum_Classic=0\n",
    "    sum_Modern=0\n",
    "    sum_Natural=0\n",
    "\n",
    "    for i in range(11) :\n",
    "        if i !=10:\n",
    "            # if np.argmax(labels[i])>0.5:\n",
    "\n",
    "            sum_Caual +=round(labels[i][0]*100)\n",
    "            sum_Classic +=round(labels[i][1]*100)\n",
    "            sum_Modern +=round(labels[i][2]*100)\n",
    "            sum_Natural +=round(labels[i][3]*100)\n",
    "            dict_a={\n",
    "                \"Photo\" : i,\n",
    "                \"Casual\" :  f\"{round(labels[i][0]*100,2)}%\",\n",
    "                \"Classic\" : f\"{round(labels[i][1]*100,2)}%\",\n",
    "                \"Modern\" :  f\"{round(labels[i][2]*100,2)}%\",\n",
    "                \"Natural\" :  f\"{round(labels[i][3]*100,2)}%\"\n",
    "            }\n",
    "\n",
    "        else:\n",
    "              dict_a={\n",
    "                \"Photo\" : \"sum\",\n",
    "                \"Casual\" :  f\"{sum_Caual/10}%\",\n",
    "                \"Classic\" : f\"{sum_Classic/10}%\",\n",
    "                \"Modern\" :  f\"{sum_Modern/10}%\",\n",
    "                \"Natural\" :  f\"{sum_Natural/10}%\"        \n",
    "            }\n",
    "\n",
    "\n",
    "        df = df.append(dict_a,ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4dd412da-889c-44be-b254-692abb6b85f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Photo</th>\n",
       "      <th>Casual</th>\n",
       "      <th>Classic</th>\n",
       "      <th>Modern</th>\n",
       "      <th>Natural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.09%</td>\n",
       "      <td>0.01%</td>\n",
       "      <td>94.91%</td>\n",
       "      <td>4.98%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31.91%</td>\n",
       "      <td>0.07%</td>\n",
       "      <td>68.0%</td>\n",
       "      <td>0.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>99.57%</td>\n",
       "      <td>0.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>19.14%</td>\n",
       "      <td>53.23%</td>\n",
       "      <td>27.34%</td>\n",
       "      <td>0.29%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.7%</td>\n",
       "      <td>0.63%</td>\n",
       "      <td>96.56%</td>\n",
       "      <td>2.11%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>6</td>\n",
       "      <td>3.02%</td>\n",
       "      <td>2.1%</td>\n",
       "      <td>1.07%</td>\n",
       "      <td>93.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>7</td>\n",
       "      <td>0.44%</td>\n",
       "      <td>86.33%</td>\n",
       "      <td>0.05%</td>\n",
       "      <td>13.17%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>8</td>\n",
       "      <td>98.74%</td>\n",
       "      <td>0.7%</td>\n",
       "      <td>0.43%</td>\n",
       "      <td>0.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>9</td>\n",
       "      <td>0.33%</td>\n",
       "      <td>9.12%</td>\n",
       "      <td>85.71%</td>\n",
       "      <td>4.83%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>sum</td>\n",
       "      <td>28.3%</td>\n",
       "      <td>12.3%</td>\n",
       "      <td>30.1%</td>\n",
       "      <td>29.3%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Photo  Casual Classic  Modern Natural\n",
       "0        0   0.09%   0.01%  94.91%   4.98%\n",
       "1        1  31.91%   0.07%   68.0%   0.02%\n",
       "2        2   0.22%    0.0%  99.57%    0.2%\n",
       "3        3  19.14%  53.23%  27.34%   0.29%\n",
       "4        4    0.7%   0.63%  96.56%   2.11%\n",
       "...    ...     ...     ...     ...     ...\n",
       "2195     6   3.02%    2.1%   1.07%  93.81%\n",
       "2196     7   0.44%  86.33%   0.05%  13.17%\n",
       "2197     8  98.74%    0.7%   0.43%   0.14%\n",
       "2198     9   0.33%   9.12%  85.71%   4.83%\n",
       "2199   sum   28.3%   12.3%   30.1%   29.3%\n",
       "\n",
       "[2200 rows x 5 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6c25a294-4d1c-4153-bed7-1f42e31ac708",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"plus-800-1000예측.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b87a9d38-e03d-4bf6-987e-d2054deb441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df[df[\"Photo\"]==\"sum\"].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3fa8c92b-8daf-4f1d-afc2-04dd5b74af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_avg = df2.drop(columns=[\"index\",\"Photo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "84553045-140a-469c-940e-6785b6603705",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_num=[ 819,\n",
    " 837,\n",
    " 838,\n",
    " 874,\n",
    " 898,\n",
    " 901,\n",
    " 907,\n",
    " 928,\n",
    " 936,\n",
    " 953,\n",
    " 954,\n",
    " 955,\n",
    " 957,\n",
    " 959,\n",
    " 965,\n",
    " 972,\n",
    " 974,\n",
    " 975,\n",
    " 979,\n",
    " 983,\n",
    " 994,\n",
    " 996,]\n",
    "del_num2 = [i-800 for i in del_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "21fb5e0f-4aba-44f8-be18-c4836bb39dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Casual</th>\n",
       "      <th>Classic</th>\n",
       "      <th>Modern</th>\n",
       "      <th>Natural</th>\n",
       "      <th>max_pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.7%</td>\n",
       "      <td>0.2%</td>\n",
       "      <td>83.3%</td>\n",
       "      <td>4.9%</td>\n",
       "      <td>Modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.3%</td>\n",
       "      <td>10.7%</td>\n",
       "      <td>56.0%</td>\n",
       "      <td>4.9%</td>\n",
       "      <td>Modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.7%</td>\n",
       "      <td>4.0%</td>\n",
       "      <td>74.1%</td>\n",
       "      <td>5.2%</td>\n",
       "      <td>Modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.4%</td>\n",
       "      <td>34.3%</td>\n",
       "      <td>20.0%</td>\n",
       "      <td>25.1%</td>\n",
       "      <td>Classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.7%</td>\n",
       "      <td>20.0%</td>\n",
       "      <td>58.1%</td>\n",
       "      <td>2.4%</td>\n",
       "      <td>Modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>42.3%</td>\n",
       "      <td>3.6%</td>\n",
       "      <td>52.9%</td>\n",
       "      <td>1.2%</td>\n",
       "      <td>Modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>39.4%</td>\n",
       "      <td>1.3%</td>\n",
       "      <td>53.6%</td>\n",
       "      <td>5.7%</td>\n",
       "      <td>Modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>33.1%</td>\n",
       "      <td>25.4%</td>\n",
       "      <td>40.3%</td>\n",
       "      <td>1.3%</td>\n",
       "      <td>Modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>32.6%</td>\n",
       "      <td>13.1%</td>\n",
       "      <td>49.3%</td>\n",
       "      <td>4.8%</td>\n",
       "      <td>Modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>9.9%</td>\n",
       "      <td>61.8%</td>\n",
       "      <td>5.4%</td>\n",
       "      <td>22.8%</td>\n",
       "      <td>Classic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Casual Classic Modern Natural  max_pre\n",
       "0    11.7%    0.2%  83.3%    4.9%   Modern\n",
       "1    28.3%   10.7%  56.0%    4.9%   Modern\n",
       "2    16.7%    4.0%  74.1%    5.2%   Modern\n",
       "3    20.4%   34.3%  20.0%   25.1%  Classic\n",
       "4    19.7%   20.0%  58.1%    2.4%   Modern\n",
       "..     ...     ...    ...     ...      ...\n",
       "173  42.3%    3.6%  52.9%    1.2%   Modern\n",
       "174  39.4%    1.3%  53.6%    5.7%   Modern\n",
       "175  33.1%   25.4%  40.3%    1.3%   Modern\n",
       "176  32.6%   13.1%  49.3%    4.8%   Modern\n",
       "177   9.9%   61.8%   5.4%   22.8%  Classic\n",
       "\n",
       "[178 rows x 5 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터 프레임\n",
    "\n",
    "# # 각 row별 가장 큰 값에 해당하는 컬럼명으로 새로운 컬럼생성\n",
    "df2_avg['max_pre'] = [ df2_avg.columns[ np.argmax( [float(data[:-1]) for data in row] ) ] for row in df2_avg.values ]\n",
    "df2_avg.drop(index=del_num2, inplace = True, axis=0)\n",
    "df2_avg.reset_index(inplace = True)\n",
    "df2_avg.drop(columns=[\"index\"],inplace =True)\n",
    "df2_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae162c4-467c-4665-8ecb-79d8c169e154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "85497547-dc7d-4e5a-adfd-b92e381ab729",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_avg.to_csv(\"plus-800-1000예측.csv-평균.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2e5bf9a9-3141-4e2b-abc5-3ca87d9e5e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modern :  105\n",
      "Natural :  10\n",
      "Casual :  47\n",
      "Classic :  16\n"
     ]
    }
   ],
   "source": [
    "print(\"Modern : \",len(df2_avg[df2_avg[\"max_pre\"]==\"Modern\"]))\n",
    "print(\"Natural : \",len(df2_avg[df2_avg[\"max_pre\"]==\"Natural\"]))\n",
    "print(\"Casual : \",len(df2_avg[df2_avg[\"max_pre\"]==\"Casual\"]))\n",
    "print(\"Classic : \",len(df2_avg[df2_avg[\"max_pre\"]==\"Classic\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "886ee6ed-2c14-4388-a163-a3858784e1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>숙소_형태</th>\n",
       "      <th>위치</th>\n",
       "      <th>가격</th>\n",
       "      <th>최대_인원수</th>\n",
       "      <th>침실개수</th>\n",
       "      <th>침대개수</th>\n",
       "      <th>욕실개수</th>\n",
       "      <th>소개글</th>\n",
       "      <th>댓글</th>\n",
       "      <th>댓글개수</th>\n",
       "      <th>평점</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>공동주택전체</td>\n",
       "      <td>세비아, 안달루시아(Andalucía), 스페인</td>\n",
       "      <td>221736</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['리모델링한 아파트의 옥상 파티오에서 일광욕을 즐기거나 공용 옥상 수영장에서 수영...</td>\n",
       "      <td>['주변은 공사 한다 시끄러웠고, 뜨거운 물이 갑자기 안나와서 고생했다.', '숙소...</td>\n",
       "      <td>228</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>공동주택전체</td>\n",
       "      <td>Lisboa, 포르투갈</td>\n",
       "      <td>172842</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['리스본 중심부에 위치한 이 독특한 아파트의 전용 발코니에서 테호강의 일몰을 감상...</td>\n",
       "      <td>['단연코 지금껏 이용해 본 에어비앤비 숙소 중 가장 훌륭했습니다. 높은 곳에 위치...</td>\n",
       "      <td>276</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>공동주택전체</td>\n",
       "      <td>멕시코시티, Ciudad de México, 멕시코</td>\n",
       "      <td>981756</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>['인증된 회사가 게스트 간의 숙소 소독 및 살균.신청일과 함께 서비스 인증서.선형...</td>\n",
       "      <td>['멋진 숙소입니다. 훌륭한 지역에 있으며 매우 깨끗하고 넓습니다. 연중무휴 경비원...</td>\n",
       "      <td>115</td>\n",
       "      <td>4.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>저택의개인실</td>\n",
       "      <td>세비아, 안달루시아(Andalucía), 스페인</td>\n",
       "      <td>187404</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['안달루시아 수도 한가운데 있는 궁전에서 깨어나고 싶으신가요? 기랄다가 내려다보이...</td>\n",
       "      <td>['너무 좋습니다블랑카는 매우 친절하고 룸 상태도 너무 좋고 불만을 갖을것이 하나 ...</td>\n",
       "      <td>341</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>공동주택전체</td>\n",
       "      <td>부다페스트(Budapest), 헝가리</td>\n",
       "      <td>186620</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['높이 솟은 커스텀 빌트인 침대에서 영화를 감상해보세요. 오페라에서 우아한 저녁을...</td>\n",
       "      <td>['이틀 머문것이 아쉬운 좋은 숙소입니다..', '미할리와 쉽게 의사소통할 수 있었...</td>\n",
       "      <td>158</td>\n",
       "      <td>4.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489</th>\n",
       "      <td>저택전체</td>\n",
       "      <td>Seminyak , 발리, 인도네시아</td>\n",
       "      <td>1005204</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['이 미적 명작에서 감각을 즐겨보세요. 엄선된 인테리어와 가구, 개별적으로 디자인...</td>\n",
       "      <td>['Airbnb의 특성상 호스트와의 커뮤니케이션이 아주 중요한데, 호스트가 직접 하...</td>\n",
       "      <td>112</td>\n",
       "      <td>4.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>공동주택전체</td>\n",
       "      <td>Praha 1, Hlavní město Praha, 체코</td>\n",
       "      <td>158476</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['채광창, 바닥의 오리엔탈 러그, 나무로 마감된 천장이 있는 주방에서 자연 채광을...</td>\n",
       "      <td>['숙소가 꼭대기 층에 위치해 있어서 걸어올라가는 데 힘들었지만, 창문 밖으로 보이...</td>\n",
       "      <td>271</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>콘도전체</td>\n",
       "      <td>바르셀로나, 카탈루냐, 스페인</td>\n",
       "      <td>111813</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['고층 아파트의 햇살이 잘 드는 발코니에서 옥상을 바라보세요. 리모델링한 복고풍 ...</td>\n",
       "      <td>['정말 좋았습니다ㅈ', '비행기 3시간 지연으로 관리인분께연락드렸고 바로답을 받았...</td>\n",
       "      <td>468</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>로프트전체</td>\n",
       "      <td>Lake Placid, 뉴욕, 미국</td>\n",
       "      <td>609292</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['창문, 스카이라이트, 프라이빗 데크에서 높은 봉우리와 올림픽 빌리지의 전망을 감...</td>\n",
       "      <td>['훌륭한 위치와 주차. 체크인 및 체크아웃이 간편합니다. 아름다운 로프트로 잘 꾸...</td>\n",
       "      <td>205</td>\n",
       "      <td>4.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>공동주택전체</td>\n",
       "      <td>Athina, 그리스</td>\n",
       "      <td>132480</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['아크로폴리스에서 도보 15분 이내의 거리에 있는 이 세련된 아파트에서 에게해의 ...</td>\n",
       "      <td>['넓은 숙소, 밝고 중심가에서 20분 거리. 좋은 경험', '코우카키 지구의 중심...</td>\n",
       "      <td>274</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3494 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       숙소_형태                               위치       가격  최대_인원수  침실개수  침대개수  \\\n",
       "0     공동주택전체       세비아, 안달루시아(Andalucía), 스페인   221736       4   1.0   1.0   \n",
       "1     공동주택전체                     Lisboa, 포르투갈   172842       4   1.0   4.0   \n",
       "2     공동주택전체     멕시코시티, Ciudad de México, 멕시코   981756       6   3.0   4.0   \n",
       "3     저택의개인실       세비아, 안달루시아(Andalucía), 스페인   187404       2   1.0   2.0   \n",
       "4     공동주택전체             부다페스트(Budapest), 헝가리   186620       2   1.0   1.0   \n",
       "...      ...                              ...      ...     ...   ...   ...   \n",
       "3489    저택전체             Seminyak , 발리, 인도네시아  1005204      10   5.0  11.0   \n",
       "3490  공동주택전체  Praha 1, Hlavní město Praha, 체코   158476       6   2.0   4.0   \n",
       "3491    콘도전체                 바르셀로나, 카탈루냐, 스페인   111813       6   4.0   5.0   \n",
       "3492   로프트전체              Lake Placid, 뉴욕, 미국   609292       4   1.0   2.0   \n",
       "3493  공동주택전체                      Athina, 그리스   132480       6   2.0   3.0   \n",
       "\n",
       "      욕실개수                                                소개글  \\\n",
       "0      1.0  ['리모델링한 아파트의 옥상 파티오에서 일광욕을 즐기거나 공용 옥상 수영장에서 수영...   \n",
       "1      1.0  ['리스본 중심부에 위치한 이 독특한 아파트의 전용 발코니에서 테호강의 일몰을 감상...   \n",
       "2      3.5  ['인증된 회사가 게스트 간의 숙소 소독 및 살균.신청일과 함께 서비스 인증서.선형...   \n",
       "3      1.0  ['안달루시아 수도 한가운데 있는 궁전에서 깨어나고 싶으신가요? 기랄다가 내려다보이...   \n",
       "4      1.0  ['높이 솟은 커스텀 빌트인 침대에서 영화를 감상해보세요. 오페라에서 우아한 저녁을...   \n",
       "...    ...                                                ...   \n",
       "3489   5.0  ['이 미적 명작에서 감각을 즐겨보세요. 엄선된 인테리어와 가구, 개별적으로 디자인...   \n",
       "3490   1.0  ['채광창, 바닥의 오리엔탈 러그, 나무로 마감된 천장이 있는 주방에서 자연 채광을...   \n",
       "3491   2.0  ['고층 아파트의 햇살이 잘 드는 발코니에서 옥상을 바라보세요. 리모델링한 복고풍 ...   \n",
       "3492   1.0  ['창문, 스카이라이트, 프라이빗 데크에서 높은 봉우리와 올림픽 빌리지의 전망을 감...   \n",
       "3493   1.0  ['아크로폴리스에서 도보 15분 이내의 거리에 있는 이 세련된 아파트에서 에게해의 ...   \n",
       "\n",
       "                                                     댓글 댓글개수    평점  \n",
       "0     ['주변은 공사 한다 시끄러웠고, 뜨거운 물이 갑자기 안나와서 고생했다.', '숙소...  228  4.89  \n",
       "1     ['단연코 지금껏 이용해 본 에어비앤비 숙소 중 가장 훌륭했습니다. 높은 곳에 위치...  276  4.92  \n",
       "2     ['멋진 숙소입니다. 훌륭한 지역에 있으며 매우 깨끗하고 넓습니다. 연중무휴 경비원...  115  4.85  \n",
       "3     ['너무 좋습니다블랑카는 매우 친절하고 룸 상태도 너무 좋고 불만을 갖을것이 하나 ...  341  4.92  \n",
       "4     ['이틀 머문것이 아쉬운 좋은 숙소입니다..', '미할리와 쉽게 의사소통할 수 있었...  158  4.88  \n",
       "...                                                 ...  ...   ...  \n",
       "3489  ['Airbnb의 특성상 호스트와의 커뮤니케이션이 아주 중요한데, 호스트가 직접 하...  112  4.95  \n",
       "3490  ['숙소가 꼭대기 층에 위치해 있어서 걸어올라가는 데 힘들었지만, 창문 밖으로 보이...  271  4.83  \n",
       "3491  ['정말 좋았습니다ㅈ', '비행기 3시간 지연으로 관리인분께연락드렸고 바로답을 받았...  468  4.80  \n",
       "3492  ['훌륭한 위치와 주차. 체크인 및 체크아웃이 간편합니다. 아름다운 로프트로 잘 꾸...  205  4.95  \n",
       "3493  ['넓은 숙소, 밝고 중심가에서 20분 거리. 좋은 경험', '코우카키 지구의 중심...  274  4.77  \n",
       "\n",
       "[3494 rows x 11 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#리뷰\n",
    "a =pd.read_csv(\"plus_comment.csv\")\n",
    "# a=a[:-1]\n",
    "a.drop(columns=[\"Unnamed: 0.1\",\"Unnamed: 0\"], inplace = True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5f53a831-74a2-4797-bfa3-8a7f2082d181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "숙소_형태     0\n",
       "위치        0\n",
       "가격        0\n",
       "최대_인원수    0\n",
       "침실개수      0\n",
       "침대개수      0\n",
       "욕실개수      0\n",
       "소개글       0\n",
       "댓글        0\n",
       "댓글개수      0\n",
       "평점        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=a.fillna(0)\n",
    "a.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0ca52557-0bdb-44ff-a75d-9da1392421bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_800_1000 = a[800:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a61f3381-17e1-4a86-8148-088132438412",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_800_1000.drop(index=del_num, inplace = True, axis=0)\n",
    "df_800_1000.reset_index(inplace = True)\n",
    "df_800_1000.drop(columns=[\"index\"],inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "61cb283b-d4f0-4ad7-9c45-e4626eb4b99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 50)\n",
    "# pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f15cb41c-c88a-4b80-9d47-9f6c7cdc0e32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>숙소_형태</th>\n",
       "      <th>위치</th>\n",
       "      <th>가격</th>\n",
       "      <th>최대_인원수</th>\n",
       "      <th>침실개수</th>\n",
       "      <th>침대개수</th>\n",
       "      <th>욕실개수</th>\n",
       "      <th>소개글</th>\n",
       "      <th>댓글</th>\n",
       "      <th>댓글개수</th>\n",
       "      <th>평점</th>\n",
       "      <th>Casual</th>\n",
       "      <th>Classic</th>\n",
       "      <th>Modern</th>\n",
       "      <th>Natural</th>\n",
       "      <th>max_pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>공동주택전체</td>\n",
       "      <td>Athina, 그리스</td>\n",
       "      <td>143310</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['고대와 유서 깊은 도시 중심가에서 대중문화와 현대 예술의 오아시스를 만나보세요....</td>\n",
       "      <td>['숙소는 위치도 좋고 깨끗하고 예뻤습니다 !! 1층이라고 해서 걱정했는데, 한국으...</td>\n",
       "      <td>423</td>\n",
       "      <td>4.87</td>\n",
       "      <td>11.7%</td>\n",
       "      <td>0.2%</td>\n",
       "      <td>83.3%</td>\n",
       "      <td>4.9%</td>\n",
       "      <td>Modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>로프트전체</td>\n",
       "      <td>발렌시아(Valencia), Comunidad Valenciana, 스페인</td>\n",
       "      <td>144883</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['현대적인 인테리어의 VT-43639-V 2층 로프트. 커다란 창문을 통해 레반테...</td>\n",
       "      <td>['마르코스는 매우 도움이 되었고 아파트에서 바라보는 풍경이 훌륭했습니다. 체크인과...</td>\n",
       "      <td>371</td>\n",
       "      <td>4.92</td>\n",
       "      <td>28.3%</td>\n",
       "      <td>10.7%</td>\n",
       "      <td>56.0%</td>\n",
       "      <td>4.9%</td>\n",
       "      <td>Modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>공동주택전체</td>\n",
       "      <td>밀라노, Lombardia, 이탈리아</td>\n",
       "      <td>271598</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['몽환적인 분위기와 인스타그램을 즐길 수 있는 코너가 마음에 드신다면, 아파트의 ...</td>\n",
       "      <td>['밀라노에서 중심가입니다 생각보다는 크지 않지만 깔끔합니다', '없음', '멋진 ...</td>\n",
       "      <td>102</td>\n",
       "      <td>4.79</td>\n",
       "      <td>16.7%</td>\n",
       "      <td>4.0%</td>\n",
       "      <td>74.1%</td>\n",
       "      <td>5.2%</td>\n",
       "      <td>Modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>공동주택전체</td>\n",
       "      <td>Warszawa, mazowieckie, 폴란드</td>\n",
       "      <td>130396</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['바르샤바의 역사적인 구시가지 한가운데에 위치한 이 매력적이고 아늑한 아파트는 폴...</td>\n",
       "      <td>['간편한 체크인과 훌륭한 위치 - 추천합니다.', '아파트의 위치는 구시가지 한복...</td>\n",
       "      <td>189</td>\n",
       "      <td>4.87</td>\n",
       "      <td>20.4%</td>\n",
       "      <td>34.3%</td>\n",
       "      <td>20.0%</td>\n",
       "      <td>25.1%</td>\n",
       "      <td>Classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>공동주택전체</td>\n",
       "      <td>Praha 8, Hlavní město Praha, 체코</td>\n",
       "      <td>93032</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['파스텔 색상의 커튼, 베개, 헤드보드에서부터 화분과 하트 모양의 분홍색에 이르기...</td>\n",
       "      <td>['두명이서 쓰기에 완벽했어요! 위치는 중심부에서 조금 떨어져 있는 정도인데 천천히...</td>\n",
       "      <td>166</td>\n",
       "      <td>4.73</td>\n",
       "      <td>19.7%</td>\n",
       "      <td>20.0%</td>\n",
       "      <td>58.1%</td>\n",
       "      <td>2.4%</td>\n",
       "      <td>Modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>공동주택전체</td>\n",
       "      <td>파리, Île-de-France, 프랑스</td>\n",
       "      <td>173880</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['영화의 세계에 헌신하는 이 주택으로 7번째 예술 작품을 감상해보세요. 이 이전 ...</td>\n",
       "      <td>['공간이 분리되어있어 좋았습니다. 티비가없어서 불편했고 스크린이있지만 사용하지못했...</td>\n",
       "      <td>307</td>\n",
       "      <td>4.85</td>\n",
       "      <td>42.3%</td>\n",
       "      <td>3.6%</td>\n",
       "      <td>52.9%</td>\n",
       "      <td>1.2%</td>\n",
       "      <td>Modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>공동주택전체</td>\n",
       "      <td>Saint-Cloud, Île-de-France, 프랑스</td>\n",
       "      <td>160003</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>['아파트는 꽃과 나무가 가득한 조용한 동네에 있으며, 넓고 밝은 68제곱미터입니다...</td>\n",
       "      <td>['이 후기는 어디서부터 시작해야 할지 모르겠지만 아파트는 하위 기준이며 에어비앤비...</td>\n",
       "      <td>128</td>\n",
       "      <td>4.79</td>\n",
       "      <td>39.4%</td>\n",
       "      <td>1.3%</td>\n",
       "      <td>53.6%</td>\n",
       "      <td>5.7%</td>\n",
       "      <td>Modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>공동주택전체</td>\n",
       "      <td>올비아, Sardegna, 이탈리아</td>\n",
       "      <td>157483</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['세련된 가구에서 창의성의 여유를 느껴보세요. 독특한 솔루션으로 편안함을 극대화하...</td>\n",
       "      <td>['집이 이뻐요! 마리아는 매우 세심하고 도움이 되었으며 커뮤니케이션이 훌륭했습니다...</td>\n",
       "      <td>111</td>\n",
       "      <td>4.97</td>\n",
       "      <td>33.1%</td>\n",
       "      <td>25.4%</td>\n",
       "      <td>40.3%</td>\n",
       "      <td>1.3%</td>\n",
       "      <td>Modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>공동주택전체</td>\n",
       "      <td>말라가, 안달루시아(Andalucía), 스페인</td>\n",
       "      <td>108664</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['조심스러운 인테리어부터 작은 디테일까지, 야외 조명이 모든 숙박을 비추는 대형 ...</td>\n",
       "      <td>['깨끗하고 편안한 숙소였습니다. 도심의 주요 관광지까지 5분 정도에 위치에 걸어가...</td>\n",
       "      <td>122</td>\n",
       "      <td>4.78</td>\n",
       "      <td>32.6%</td>\n",
       "      <td>13.1%</td>\n",
       "      <td>49.3%</td>\n",
       "      <td>4.8%</td>\n",
       "      <td>Modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>게스트스위트전체</td>\n",
       "      <td>아테네, Attica, 그리스</td>\n",
       "      <td>88820</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['이 특징적인 숙소에서 프랑스 예술가 크리스토프 레이어가 만든 타일로 된 욕조에서...</td>\n",
       "      <td>['완전 강추합니당. 약간 불이 어둡긴하지만 집 분위기로 다 감당가능합니당. 복층 ...</td>\n",
       "      <td>442</td>\n",
       "      <td>4.85</td>\n",
       "      <td>9.9%</td>\n",
       "      <td>61.8%</td>\n",
       "      <td>5.4%</td>\n",
       "      <td>22.8%</td>\n",
       "      <td>Classic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        숙소_형태                                         위치      가격  최대_인원수  \\\n",
       "0      공동주택전체                                Athina, 그리스  143310       4   \n",
       "1       로프트전체  발렌시아(Valencia), Comunidad Valenciana, 스페인  144883       2   \n",
       "2      공동주택전체                       밀라노, Lombardia, 이탈리아  271598       6   \n",
       "3      공동주택전체                 Warszawa, mazowieckie, 폴란드  130396       4   \n",
       "4      공동주택전체            Praha 8, Hlavní město Praha, 체코   93032       3   \n",
       "..        ...                                        ...     ...     ...   \n",
       "173    공동주택전체                     파리, Île-de-France, 프랑스  173880       2   \n",
       "174    공동주택전체            Saint-Cloud, Île-de-France, 프랑스  160003       4   \n",
       "175    공동주택전체                        올비아, Sardegna, 이탈리아  157483       4   \n",
       "176    공동주택전체                 말라가, 안달루시아(Andalucía), 스페인  108664       4   \n",
       "177  게스트스위트전체                           아테네, Attica, 그리스   88820       2   \n",
       "\n",
       "     침실개수  침대개수  욕실개수                                                소개글  \\\n",
       "0     NaN   2.0   1.0  ['고대와 유서 깊은 도시 중심가에서 대중문화와 현대 예술의 오아시스를 만나보세요....   \n",
       "1     1.0   1.0   1.0  ['현대적인 인테리어의 VT-43639-V 2층 로프트. 커다란 창문을 통해 레반테...   \n",
       "2     2.0   2.0   1.0  ['몽환적인 분위기와 인스타그램을 즐길 수 있는 코너가 마음에 드신다면, 아파트의 ...   \n",
       "3     2.0   2.0   1.0  ['바르샤바의 역사적인 구시가지 한가운데에 위치한 이 매력적이고 아늑한 아파트는 폴...   \n",
       "4     1.0   2.0   1.0  ['파스텔 색상의 커튼, 베개, 헤드보드에서부터 화분과 하트 모양의 분홍색에 이르기...   \n",
       "..    ...   ...   ...                                                ...   \n",
       "173   1.0   1.0   1.0  ['영화의 세계에 헌신하는 이 주택으로 7번째 예술 작품을 감상해보세요. 이 이전 ...   \n",
       "174   1.0   1.0   1.5  ['아파트는 꽃과 나무가 가득한 조용한 동네에 있으며, 넓고 밝은 68제곱미터입니다...   \n",
       "175   1.0   2.0   1.0  ['세련된 가구에서 창의성의 여유를 느껴보세요. 독특한 솔루션으로 편안함을 극대화하...   \n",
       "176   2.0   3.0   1.0  ['조심스러운 인테리어부터 작은 디테일까지, 야외 조명이 모든 숙박을 비추는 대형 ...   \n",
       "177   1.0   1.0   1.0  ['이 특징적인 숙소에서 프랑스 예술가 크리스토프 레이어가 만든 타일로 된 욕조에서...   \n",
       "\n",
       "                                                    댓글 댓글개수    평점 Casual  \\\n",
       "0    ['숙소는 위치도 좋고 깨끗하고 예뻤습니다 !! 1층이라고 해서 걱정했는데, 한국으...  423  4.87  11.7%   \n",
       "1    ['마르코스는 매우 도움이 되었고 아파트에서 바라보는 풍경이 훌륭했습니다. 체크인과...  371  4.92  28.3%   \n",
       "2    ['밀라노에서 중심가입니다 생각보다는 크지 않지만 깔끔합니다', '없음', '멋진 ...  102  4.79  16.7%   \n",
       "3    ['간편한 체크인과 훌륭한 위치 - 추천합니다.', '아파트의 위치는 구시가지 한복...  189  4.87  20.4%   \n",
       "4    ['두명이서 쓰기에 완벽했어요! 위치는 중심부에서 조금 떨어져 있는 정도인데 천천히...  166  4.73  19.7%   \n",
       "..                                                 ...  ...   ...    ...   \n",
       "173  ['공간이 분리되어있어 좋았습니다. 티비가없어서 불편했고 스크린이있지만 사용하지못했...  307  4.85  42.3%   \n",
       "174  ['이 후기는 어디서부터 시작해야 할지 모르겠지만 아파트는 하위 기준이며 에어비앤비...  128  4.79  39.4%   \n",
       "175  ['집이 이뻐요! 마리아는 매우 세심하고 도움이 되었으며 커뮤니케이션이 훌륭했습니다...  111  4.97  33.1%   \n",
       "176  ['깨끗하고 편안한 숙소였습니다. 도심의 주요 관광지까지 5분 정도에 위치에 걸어가...  122  4.78  32.6%   \n",
       "177  ['완전 강추합니당. 약간 불이 어둡긴하지만 집 분위기로 다 감당가능합니당. 복층 ...  442  4.85   9.9%   \n",
       "\n",
       "    Classic Modern Natural  max_pre  \n",
       "0      0.2%  83.3%    4.9%   Modern  \n",
       "1     10.7%  56.0%    4.9%   Modern  \n",
       "2      4.0%  74.1%    5.2%   Modern  \n",
       "3     34.3%  20.0%   25.1%  Classic  \n",
       "4     20.0%  58.1%    2.4%   Modern  \n",
       "..      ...    ...     ...      ...  \n",
       "173    3.6%  52.9%    1.2%   Modern  \n",
       "174    1.3%  53.6%    5.7%   Modern  \n",
       "175   25.4%  40.3%    1.3%   Modern  \n",
       "176   13.1%  49.3%    4.8%   Modern  \n",
       "177   61.8%   5.4%   22.8%  Classic  \n",
       "\n",
       "[178 rows x 16 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_800_1000 = pd.concat([df_800_1000,df2_avg],axis=1)\n",
    "df_800_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aa2eb1aa-6924-439e-92f6-47e0ec41cde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2100_2400.to_csv(\"plus-800-1000_리뷰+사진예측.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2d6565-cc17-4dfe-9fd2-93d12f9cd991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479b0bcd-8928-48e1-8879-f4335b0af939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a54917-3b35-4d43-900c-d025f3f9ac06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f90017-4a58-41e0-b75f-caea9113c908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f6133-96b5-4b88-bb52-2d89978f3b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1ef670-259e-4867-926b-87d6a1a09ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b52cd7-29ba-42d4-8fc6-f26ca7ee95aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_py",
   "language": "python",
   "name": "gpu_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
